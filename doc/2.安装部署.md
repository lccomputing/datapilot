# 服务端部署

> sky datapilot 正常运行需要开放如下网络端口，管理员可根据实际环境要求，在网络侧开放相关端口。

| 组件       | 默认端口       | 说明                                   |
| ---------- | -------------- | -------------------------------------- |
| hbo-pc     | 80             | 前端服务，浏览器访问端口               |
| clickhouse | 8123<br />9009 | 数据采集存储服务                       |
| mysql      | 3306           | 后端数据存储服务                       |
| lcc-hbo    | 8077           | 后端核心服务，为前端页面和hook提供接口 |

部署sky datapilot节点和大数据集群网络要求

1. 大数据集群的所有主机可以访问到服务端后端服务：http://{HOST_IP}:8077（注：{HOST_IP}为服务端主机IP）
2. 服务端主机能够访问要采集的任务类型的history服务
   - 采集yarn app：resource manager webui（http://ip:8088）
   - 采集MapReduce job：job history（http://ip:19888）
   - 采集spark app：spark history（http://ip:18088）
   - 采集impala：impala daemon webui（http://ip:25000）

## docker compose部署

### 部署服务器要求

1. CPU&内存
   - 日均任务<1k，4核8G
   - 日均任务<1w，8核16G
   - 日均任务>1w，8核32G
   - 日均任务>10w，16核32G

2. 磁盘
   - 日均任务<1k，50G SSD 数据盘
   - 日均任务<1w，100G SSD 数据盘
   - 日均任务>1w，300G SSD 数据盘
   - 日均任务>10w，500G SSD 数据盘

3. 操作系统：linux(x86_64架构)，推荐CentOS 7.9

4. 系统时区检查

   ```
   # 检查系统时区是否为东八区，如果不是东八区需要手动修改
   ll /etc/localtime
   lrwxrwxrwx. 1 root root 35 Oct 13  2023 /etc/localtime -> ../usr/share/zoneinfo/Asia/Shanghai
   ```

### 部署流程

1. 获取服务端安装包

   ```
   wget http://lcc-sky-datapilot.oss-cn-hangzhou.aliyuncs.com/server/server-community-latest.zip
   ```

2. 解压安装包

   ```
   unzip server-community-latest.zip
   ```

3. 部署docker

   如果已存在docker，且docker api version >= 1.4.1，可跳过该步骤

   ```
   # 解压docker二进制文件
   tar xzvf docker-23.0.2.tar.gz
   
   # 将二进制文件移动到可执行路径上的目录，例如/usr/bin/
   sudo cp docker/* /usr/bin/
   
   # 启动 Docker 守护进程
   sudo dockerd &
   
   # 查看docker版本，确认docker服务拉起
   docker version
   ```

4. 部署docker-compose，如果已存在docker-compose，可跳过该步骤

   ```
   # 将二进制文件移动到/usr/local/bin/
   cp docker-compose /usr/local/bin/docker-compose
   
   # 更改权限
   sudo chmod +x /usr/local/bin/docker-compose
   
   # 查看docker-compose版本，确认生效
   docker-compose --version
   ```

5. 导入镜像

   ```
   # 导入镜像 
   docker load -i optimizer_images.tar
   ```

6. 配置mysql和clickhouse存储挂载到数据盘

   ```
   # 编辑optimizer-etc目录下docker-compose.yaml文件
   # 配置mysql挂载目录
     mysql:
       # 省略...
       volumes:
         - /etc/localtime:/etc/localtime:ro
         - ./mysql-init/:/docker-entrypoint-initdb.d/
         # 修改 MYSQL_DATA_PATH 为自定义 clickhouse 存储目录
         - MYSQL_DATA_PATH:/var/lib/mysql/
         - ./etc/my.conf:/etc/my.cnf
   
   # 配置clickhouse挂载目录
     clickhouse:
       # 省略...
       volumes:
         - /etc/localtime:/etc/localtime:ro
         - ./etc/users.xml:/etc/clickhouse-server/users.xml
         - ./etc/disable_metric_log.xml:/etc/clickhouse-server/config.d/disable_metric_log.xml
         # 修改 CLICKHOUSE_DATA_PATH 为自定义 clickhouse 存储目录
         - CLICKHOUSE_DATA_PATH:/var/lib/clickhouse
         - ./clickhouse/log/:/var/log/clickhouse-server/
   ```

7. 启动/关停服务端

   ```
   cd optimizer-etc
   # 启动
   docker-compose -f docker-compose.yaml up -d
   
   #停止
   docker-compose -f docker-compose.yaml down
   ```

8. 访问前端

   访问 http://{HOST_IP}，默认用户名/密码：admin/Lccadmin.

9. 获取并激活license

   请访问[官网](http://www.lccomputing.com)申请试用license，申请完成后邮箱会收到一份license文件，在前端许可证注册页面将license文件上传，扫码后输入验证码激活服务。

# hook部署

​	hook需要部署在大数据任务提交的网关节点（即部署有任务提交客户端，且从该节点发起任务提交请求的节点），通常会有多个网关节点，可以灰度部署部分网关节点，部署并验证完成后可以在全部网关节点部署。

## 部署流程

1. 获取hook包
   ```bash
   cd /opt
   wget http://lcc-sky-datapilot.oss-cn-hangzhou.aliyuncs.com/hook/hook-community-latest.zip
   unzip hook-community-latest.zip
   hadoop fs -mkdir /lcc
   hadoop fs -put -d -f hook-community-latest /lcc
   ```

2. 配置（以下设置值中的**http://hbo-pc-host**需要被替换为**服务端部署流程-8**中的**http://{HOST_IP}**）
- Spark（包括spark-submit、spark-sql、pyspark任务）
   ```bash
   # 修改hive-site.xml
   # 以下配置追加到当前值后面即可，若没有可以新建
   spark.yarn.dist.files=已有值,hdfs:///lcc/hook-community-latest/spark/lcc-jvm-profiler-1.0.jar
   spark.executor.extraJavaOptions=已有值 -javaagent:lcc-jvm-profiler-1.0.jar=reporter=http://hbo-pc-host
   
   # 在spark-env.sh中添加
   # 注意：请确保gateway机器上有该文件/opt/hook-community-latest/spark/lcc-hook-agent-spark-1.0.jar，否则无法采集到driver数据
   if [[ -e "/opt/hook-community-latest/spark/lcc-hook-agent-spark-1.0.jar" && ! "${SPARK_SUBMIT_OPTS}" =~ "-javaagent:/opt/hook-community-latest/spark/lcc-hook-agent-spark-1.0.jar" ]]; then
     export SPARK_SUBMIT_OPTS="${SPARK_SUBMIT_OPTS} -javaagent:/opt/hook-community-latest/spark/lcc-hook-agent-spark-1.0.jar"
   fi
   ```

- Hive on Spark（如果是通过hiveserver2提交，请修改hiveserver2的配置）
   ```bash
  # 修改hive-site.xml
  # 以下配置追加到当前值后面即可，若没有可以新建
   spark.yarn.dist.files=已有值,hdfs:///lcc/hook-community-latest/spark/lcc-jvm-profiler-1.0.jar
   spark.executor.extraJavaOptions=已有值 -javaagent:lcc-jvm-profiler-1.0.jar=reporter=http://hbo-pc-host
   spark.driver.extraJavaOptions=已有值 -javaagent:lcc-jvm-profiler-1.0.jar=reporter=http://hbo-pc-host
  ```

- Hive on Tez（如果是通过hiveserver2提交，请修改hiveserver2的配置）
   ```bash
  # 修改tez-site.xml
  # 以下配置追加到当前值后面即可，若没有可以新建
   tez.aux.uris=已有值,${fs.defaultFS}/lcc/hook-community-latest/tez/
   
   # 由于tez.am.launch.cmd-opts的默认值为
   # -XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps -XX:+UseNUMA -XX:+UseParallelGC
   # 因此如果当前没有设置值则使用
   tez.am.launch.cmd-opts=-XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps -XX:+UseNUMA -XX:+UseParallelGC -javaagent:lcc-hook-agent-tez-1.0.jar=reporter=http://hbo-pc-host
   
   # 如果当前已经有设置值则使用
   tez.am.launch.cmd-opts=已有值 -javaagent:lcc-hook-agent-tez-1.0.jar=reporter=http://hbo-pc-host
  ```

# agent部署

​	agent核心功能是为小文件治理以及hive冷热数据扫描服务的客户端工具，如果需要使用到上述功能，需要安装agent。

## 前置条件

- 部署节点：可独立部署在有客户端的客户机上也可部署在服务端上
- 服务器规格：CPU&内存  至少1核2G  磁盘：>=20G SSD/ HDD 都可
- 操作系统：linux(x86_64架构)，推荐CentOS 7.9 java版本8及以上 
- lcc-agent 安装后cgroup默认限制2G内存，按照执行任务的并发情况适当调整，调整位置为/etc/systemd/system/lcc-agent.service 
- 网络及客户端要求   ✔️代表当前功能需要    ○代表按需可选

| 产品功能与大数据服务要求  | 小文件优化 | 冷热数据优化 |
| ------------------------- | ---------- | ------------ |
| 与hive metastore网络打通  | ✔️          | ✔️            |
| 与metastore mysql网络打通 | ✔️          |              |
| 与NameNode网络打通        | ✔️          | ✔️            |
| 访问hdfs客户端            | ✔️          | ○            |
| 访问hive客户端            | ✔️          | ✔️            |

## 部署安装及启动

```
wget http://lcc-sky-datapilot.oss-cn-hangzhou.aliyuncs.com/agent/agent-community-latest.rpm
# 安装
rpm -ivh agent-community-latest.rpm

#查询软件包的详细信息
rpm -qi lcc-agent 
#卸载
rpm -e lcc-agent
#升级
rpm -Uvh lcc-agent-*.rpm
# 修改配置参数
vim  /etc/lcc-agent/lcc-agent.toml
#修改[hboServerParam].addr 修改为服务端地址 eg:10.80.98.144:8077
service  lcc-agent start
# 重启服 service  lcc-agent restart
# 停止服务 service  lcc-agent stop
# 查看日志 /var/lib/lcc-agent/lcc-agent.log
```
观察日志/var/lib/lcc-agent/lcc-agent.log是否有ERROR，如正常跟服务端连接成功则正常启动